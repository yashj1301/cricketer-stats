{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "class Cricketer_Stats_Scraper:\n",
    "\n",
    "    def __init__(self, player_name):\n",
    "        self.player_name = player_name\n",
    "        self.player_id = None\n",
    "        self.player_url = None\n",
    "    \n",
    "        # Initialize class variables for storing stats\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.player_info = None\n",
    "\n",
    "        # Set up the WebDriver and open the search URL\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--headless\")  # Run in headless mode\n",
    "        options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "        print(\"Setting up WebDriver...\")\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "        # Call get_player_url() to fetch the player's URL and ID when the object is initialized\n",
    "        self.get_player_url()\n",
    "\n",
    "    def get_player_url(self):\n",
    "        start_time = time.time()\n",
    "        print(f\"Extracting {self.player_name}'s player URL and Player ID....\")\n",
    "        search_url = f\"https://search.espncricinfo.com/ci/content/site/search.html?search={self.player_name.lower().replace(' ', '%20')};type=player\"\n",
    "        self.driver.get(search_url)\n",
    "\n",
    "        try:\n",
    "            player_link_element = self.driver.find_element(By.CSS_SELECTOR, \"h3.name.link-cta a\")\n",
    "            self.player_url = player_link_element.get_attribute(\"href\")\n",
    "            self.player_id = self.player_url.split('-')[-1]\n",
    "            print(f\"Extraction Successful for {self.player_name}.\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken to extract URL: {end_time - start_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting {self.player_name}'s url:\", e)\n",
    "            return None, None\n",
    "\n",
    "    def extract_inns_data(self, record_type):\n",
    "        start_time = time.time()\n",
    "        print(f\"Starting extraction of {self.player_name}'s {record_type} stats....\")\n",
    "        \n",
    "        # Construct the search URL based on record_type (batting, bowling, etc.)\n",
    "        search_url = f\"https://stats.espncricinfo.com/ci/engine/player/{self.player_id}.html?class=11;template=results;type={record_type};view=innings\"\n",
    "        \n",
    "        # Open the URL\n",
    "        self.driver.get(search_url)\n",
    "\n",
    "        # Step 1: Extract the headers of the table\n",
    "        headers = self.driver.find_elements(By.CSS_SELECTOR, \"thead tr.headlinks th\")\n",
    "        header_names = [header.text for header in headers if header.text != ''] + ['Match id']  # Add match_id column name\n",
    "        \n",
    "        # Step 2: Extract the data from the 4th tbody\n",
    "        rows = self.driver.find_elements(By.XPATH, \"(//tbody)[4]//tr\")\n",
    "        \n",
    "        # Step 3: Extract the data column-wise and store it in a list\n",
    "        player_data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            row_data = [cell.text for cell in cells if cell.text != '']\n",
    "            player_data.append(row_data)\n",
    "        \n",
    "        # Step 4: Create a DataFrame from the extracted data\n",
    "        innings_data = pd.DataFrame(player_data, columns=header_names)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Extracted {innings_data.shape[0]} records in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        return innings_data\n",
    "\n",
    "    def extract_player_info(self):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting extraction of {self.player_name}'s personal info....\")\n",
    "            \n",
    "            # Start by opening the player info URL\n",
    "            self.driver.get(self.player_url)\n",
    "\n",
    "            # Step 1: Extract headers within the specified div tag\n",
    "            headers = self.driver.find_elements(By.XPATH, \"//div[@class='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8']//p[@class='ds-text-tight-m ds-font-regular ds-uppercase ds-text-typo-mid3']\")\n",
    "            header_names = ['Player ID','Player URL']+[header.text for header in headers]\n",
    "\n",
    "            # Step 2: Extract values within the specified div tag\n",
    "            values = self.driver.find_elements(By.XPATH, \"//div[@class='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8']//span[@class='ds-text-title-s ds-font-bold ds-text-typo']\")\n",
    "            value_texts = [self.player_id,self.player_url]+[value.text for value in values]\n",
    "\n",
    "            # Step 3: Create a DataFrame from the extracted data\n",
    "            player_info = pd.DataFrame([value_texts], columns=header_names)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"Extracted player info in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            return player_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting {self.player_name}'s personal info:\", e)\n",
    "            return None\n",
    "\n",
    "    def get_player_stats(self, stats_type=\"all\"):\n",
    "        try:\n",
    "            # Ensure that player ID or player URL is available\n",
    "            if not (self.player_id or self.player_url):\n",
    "                print(\"Player ID is not available. Run get_player_url() first.\")\n",
    "                return\n",
    "            \n",
    "            # Fetch personal information if 'personal_info' is passed\n",
    "            if stats_type == \"personal_info\":\n",
    "                self.player_info = self.extract_player_info()\n",
    "            \n",
    "            # Fetch batting stats if 'all' or 'batting' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"batting\":\n",
    "                self.battingstats = self.extract_inns_data('batting')\n",
    "\n",
    "            # Fetch bowling stats if 'all' or 'bowling' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"bowling\":\n",
    "                self.bowlingstats = self.extract_inns_data('bowling')\n",
    "\n",
    "            # Check if the player is an all-rounder and fetch all-round stats\n",
    "            if stats_type == \"all\" or stats_type == \"allround\":\n",
    "                self.player_info = self.extract_player_info()\n",
    "                if self.player_info is not None and 'allround' in self.player_info['PLAYING ROLE'][0].lower():\n",
    "                    self.allroundstats = self.extract_inns_data('allround')\n",
    "\n",
    "            # Fetch fielding stats if 'all' or 'fielding' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"fielding\":\n",
    "                self.fieldingstats = self.extract_inns_data('fielding')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting stats for {self.player_name}: \", e)\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "            print(\"WebDriver closed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error while closing the WebDriver:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting Ground Information\n",
    "\n",
    "The following functions are built to extract ground information. However, these are very resource-intensive, so we will take it up later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_links(player_id):\n",
    "    \"\"\"\n",
    "    This function extracts ground links from the player innings data, ensuring no duplicate ground info is scraped.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize the DataFrame to store ground info\n",
    "    ground_info_df = pd.DataFrame(columns=[\"Ground ID\", \"Stadium Name\", \"Location\", \"Home Team\", \"Image URL\"])\n",
    "\n",
    "    # Set up the WebDriver for scraping\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    # Scrape Player Stats Page\n",
    "    search_url = f\"https://stats.espncricinfo.com/ci/engine/player/{player_id}.html?class=11;template=results;type=batting;view=innings\"\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Extract ground links from innings data\n",
    "    rows = driver.find_elements(By.XPATH, \"(//tbody)[4]//tr\")\n",
    "    ground_links = []\n",
    "    \n",
    "    for row in rows:\n",
    "        try:\n",
    "            ground_name_element = row.find_element(By.XPATH, \".//td[contains(@class, 'left')][2]/a\")\n",
    "            ground_name = ground_name_element.text\n",
    "            ground_link = ground_name_element.get_attribute('href')\n",
    "            ground_links.append((ground_name, ground_link))\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting ground data: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Step 2: Check if the ground has already been scraped (exists in ground_info DataFrame)\n",
    "    for ground_name, ground_link in ground_links:\n",
    "        if ground_name not in ground_info_df['Stadium Name'].values:\n",
    "            # Create a new DataFrame for the new ground\n",
    "            new_data = pd.DataFrame({\"Stadium Name\": [ground_name], \"Ground Link\": [ground_link]})\n",
    "            ground_info_df = pd.concat([ground_info_df, new_data], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Ground {ground_name} has already been scraped. Skipping.\")\n",
    "\n",
    "    # Step 3: Extract ground info for each link and append it to the ground_info_df\n",
    "    for ground_link in ground_info_df['Ground Link']:\n",
    "        ground_info_df = extract_ground_info(ground_link, ground_info_df)\n",
    "    \n",
    "    driver.quit()\n",
    "    return ground_info_df\n",
    "\n",
    "def extract_ground_info(ground_url, ground_info_df):\n",
    "    \"\"\"\n",
    "    This function extracts ground information (ID, stadium name, location, home team, image URL)\n",
    "    from a given ground URL and appends the data to the provided dataframe.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Set up the WebDriver for scraping ground info\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    driver.get(ground_url)\n",
    "    \n",
    "    try:\n",
    "        # 1. Ground ID (numeric portion of the URL)\n",
    "        ground_id = ground_url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # 2. Ground image URL\n",
    "        img_element = driver.find_element(By.XPATH, \"//div[@class='ds-p-0']//img[1]\")\n",
    "        image_url = img_element.get_attribute(\"src\")\n",
    "        \n",
    "        # 3. Stadium Name\n",
    "        stadium_name = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-title-m') and contains(@class, 'ds-font-bold')]\").text\n",
    "        \n",
    "        # 4. Location (City)\n",
    "        location = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-compact-s') and contains(@class, 'ds-font-bold')]\").text.strip().replace(\"\\n\", \", \")\n",
    "        \n",
    "        # 5. Home Team (Country)\n",
    "        home_team_text = driver.find_element(By.XPATH, \"//span[contains(text(), 'Grounds in')]\").text\n",
    "        home_team = home_team_text.split(\"Grounds in\")[-1].strip()\n",
    "        \n",
    "        # Prepare the ground info as a dictionary\n",
    "        ground_info = pd.DataFrame({\n",
    "            \"Ground ID\": [ground_id],\n",
    "            \"Stadium Name\": [stadium_name],\n",
    "            \"Location\": [location],\n",
    "            \"Home Team\": [home_team],\n",
    "            \"Image URL\": [image_url]\n",
    "        })\n",
    "        \n",
    "        # Append the ground info to the DataFrame\n",
    "        ground_info_df = pd.concat([ground_info_df,ground_info], ignore_index=True)\n",
    "        print(f\"Extracted info for ground {stadium_name} in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while extracting info for {ground_url}: {e}\")\n",
    "    \n",
    "    driver.quit()\n",
    "    return ground_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground ID</th>\n",
       "      <th>Stadium Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rangiri-dambulla-international-stadium-59368</td>\n",
       "      <td>Rangiri Dambulla International Stadium</td>\n",
       "      <td>Dambulla</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>https://img1.hscicdn.com/image/upload/f_auto,t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Ground ID  \\\n",
       "0  rangiri-dambulla-international-stadium-59368   \n",
       "\n",
       "                             Stadium Name  Location  Home Team  \\\n",
       "0  Rangiri Dambulla International Stadium  Dambulla  Sri Lanka   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://img1.hscicdn.com/image/upload/f_auto,t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_url = 'https://www.espncricinfo.com/cricket-grounds/rangiri-dambulla-international-stadium-59368'\n",
    "\n",
    "# Set up the WebDriver for scraping ground info\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "driver.get(ground_url)\n",
    "    \n",
    "try:\n",
    "    # 1. Ground ID (numeric portion of the URL)\n",
    "    ground_id = ground_url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "    # 2. Ground image URL\n",
    "    img_element = driver.find_element(By.XPATH, \"//div[@class='ds-p-0']//img\")\n",
    "    image_url = img_element.get_attribute(\"src\")\n",
    "        \n",
    "        # 3. Stadium Name\n",
    "    stadium_name = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-title-m') and contains(@class, 'ds-font-bold')]\").text\n",
    "        \n",
    "    # 4. Location (City)\n",
    "    location = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-compact-s') and contains(@class, 'ds-font-bold')]\").text.strip().replace(\"\\n\", \", \")\n",
    "        \n",
    "    # 5. Home Team (Country)\n",
    "    home_team_text = driver.find_element(By.XPATH, \"//span[contains(text(), 'Grounds in')]\").text\n",
    "    home_team = home_team_text.split(\"Grounds in\")[-1].strip()\n",
    "        \n",
    "    # Prepare the ground info as a dictionary\n",
    "    ground_info = pd.DataFrame({\n",
    "            \"Ground ID\": [ground_id],\n",
    "            \"Stadium Name\": [stadium_name],\n",
    "            \"Location\": [location],\n",
    "            \"Home Team\": [home_team],\n",
    "            \"Image URL\": [image_url]\n",
    "        })\n",
    "\n",
    "except Exception as e : print(e)\n",
    "    \n",
    "ground_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id = 253802\n",
    "grounds = extract_ground_links(player_id)\n",
    "\n",
    "grounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Cricketer_Stats_Transformer:\n",
    "    \n",
    "    def __init__(self, player_name):\n",
    "        self.player_name = player_name\n",
    "        self.player_info = None\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.player_id = None\n",
    "        self.player_url = None\n",
    "\n",
    "    #transforming data\n",
    "\n",
    "    def transform_data(self,df):\n",
    "        \n",
    "        #STEP 1: Replacing incorrect values. \n",
    "        repl_dict = {\n",
    "            '*':'',\n",
    "            'DNB':np.nan,\n",
    "            'TDNB':np.nan,\n",
    "            'DNF':np.nan,\n",
    "            'TDNF':np.nan,\n",
    "            '-':np.nan\n",
    "            }\n",
    "\n",
    "        df = df.replace(repl_dict)\n",
    "\n",
    "        #STEP 2: Opposition column\n",
    "        df['Format'] = df['Opposition'].str.extract(r'(^.*?)\\sv\\s')\n",
    "        df['Opposition'] = df['Opposition'].str.extract(r'\\sv\\s(.*?$)')\n",
    "\n",
    "        #STEP 3: Ground column\n",
    "        ground_mapping = {\n",
    "        \"Colombo (SSC)\": \"Colombo\",\n",
    "        \"Colombo (PSS)\": \"Colombo\",\n",
    "        \"Colombo (RPS)\": \"Colombo\",\n",
    "        \"Eden Gardens\": \"Kolkata\",\n",
    "        \"Wankhede\": \"Mumbai\",\n",
    "        \"Brabourne\": \"Mumbai\",\n",
    "        \"Kingston\": \"Kingston Jamaica\",\n",
    "        \"The Oval\": \"London\",\n",
    "        \"Lord's\": \"London\",\n",
    "        \"W.A.C.A\": \"Perth\",\n",
    "        \"Dharamsala\": \"Dharamshala\",\n",
    "        \"Hamilton\": \"Hamilton Waikato\",\n",
    "        \"Fatullah\": \"Fatullah Dhaka\",\n",
    "        \"Providence\": \"Providence Guyana\",\n",
    "        \"Dubai (DICS)\": \"Dubai\",\n",
    "        \"Chattogram\": \"Chattogram Chittagong\"\n",
    "        }\n",
    "\n",
    "        df['Ground']=df['Ground'].replace(ground_mapping)\n",
    "        df = df.rename(columns={'Ground':'Location'})\n",
    "\n",
    "        #STEP 4: START DATE\n",
    "        df['Start Date'] = df['Start Date'].astype('datetime64[ns]')\n",
    "\n",
    "        #STEP 5: MATCH ID\n",
    "        df['Match id']='#'+df['Match id'].str.extract(r'(\\d+$)')\n",
    "        df = df.rename(columns={'Match id':'Match ID'})\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def final_df(self,df,common_cols,custom_cols):\n",
    "        if df is not None:\n",
    "            print(\"Starting transformation...\")\n",
    "            df = self.transform_data(df)\n",
    "            print(\"Transformation complete.\")\n",
    "            return df[ common_cols[:-2] + custom_cols + common_cols[-2:] ]\n",
    "\n",
    "    def process_data(self,type=\"all\"):\n",
    "\n",
    "        common = ['Match ID','Start Date','Format','Inns','Opposition','Location']\n",
    "        batcols = ['Pos','Runs','BF','4s','6s','SR','Mins','Dismissal']\n",
    "        bowlcols = ['Pos','Overs','Mdns','Runs','Wkts','Econ']\n",
    "        fieldcols = ['Dis','Ct']\n",
    "        allroundcols = ['Score','Overs','Conc','Wkts','Ct','St']\n",
    "\n",
    "        try:\n",
    "        \n",
    "            # Process batting stats\n",
    "            if type == 'all' or type == 'batting':\n",
    "                self.battingstats = self.final_df(self.battingstats, common, batcols)\n",
    "\n",
    "            # Process bowling stats\n",
    "            if type == 'all' or type == 'bowling':\n",
    "                self.bowlingstats = self.final_df(self.bowlingstats, common, bowlcols)\n",
    "\n",
    "            # Process fielding stats\n",
    "            if type == 'all' or type == 'fielding':\n",
    "                self.fieldingstats = self.final_df(self.fieldingstats, common, fieldcols)\n",
    "\n",
    "            # Process allround stats\n",
    "            if type == 'all' or type == 'allround':\n",
    "                if self.player_info is not None and 'allround' in self.player_info['PLAYING ROLE'][0].lower():\n",
    "                    self.allroundstats = self.final_df(self.allroundstats, common, allroundcols)\n",
    "\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing data for {self.player_name}: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "class CricketerStatsLoader:\n",
    "    def __init__(self, player_name, data_type=\"raw\"):\n",
    "        self.player_name = player_name.lower().replace(\" \", \"_\")\n",
    "        self.data_type = data_type  # 'raw' or 'tf'\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.player_info = None\n",
    "\n",
    "    def ensure_bucket_exists(self, bucket_name):\n",
    "        \"\"\"Checks if the bucket exists; if not, creates it.\"\"\"\n",
    "        client = storage.Client()\n",
    "        bucket = client.lookup_bucket(bucket_name)\n",
    "\n",
    "        if not bucket:\n",
    "            print(f\"🛠️ Bucket '{bucket_name}' does not exist. Creating it...\")\n",
    "            bucket = client.create_bucket(bucket_name)\n",
    "            print(f\"✅ Bucket '{bucket_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"✅ Bucket '{bucket_name}' already exists.\")\n",
    "\n",
    "    def upload_df_to_gcs(self, bucket_name, destination_blob_name, df):\n",
    "        \"\"\"Uploads a Pandas DataFrame as a CSV file to Google Cloud Storage.\"\"\"\n",
    "        if df is None or df.empty:\n",
    "            print(f\"⚠️ Warning: {destination_blob_name} is empty, skipping upload.\")\n",
    "            return\n",
    "\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "        # Convert DataFrame to CSV in memory (Binary Buffer)\n",
    "        buffer = BytesIO()\n",
    "        df.to_csv(buffer, index=False)\n",
    "        buffer.seek(0)  # Reset buffer position\n",
    "\n",
    "        # Upload directly from memory\n",
    "        blob.upload_from_file(buffer, content_type=\"text/csv\")\n",
    "        print(f\"✅ File uploaded to GCS: gs://{bucket_name}/{destination_blob_name}\")\n",
    "\n",
    "    def download_df_from_gcs(self, bucket_name, stat_type):\n",
    "        \"\"\"Downloads a specific type of cricket stats from GCS into a Pandas DataFrame.\n",
    "    \n",
    "        Args:\n",
    "            bucket_name (str): Google Cloud Storage bucket name.\n",
    "            stat_type (str): Type of data to fetch (e.g., \"batting\", \"bowling\", \"fielding\", \"allround\", \"personal_info\").\n",
    "    \n",
    "        Returns:\n",
    "            pd.DataFrame: The downloaded DataFrame, or None if the file is missing.\n",
    "        \"\"\"\n",
    "        # Construct the full GCS path based on the player name, data type, and stat type\n",
    "        file_name_map = {\n",
    "            \"batting\": \"batting_stats.csv\",\n",
    "            \"bowling\": \"bowling_stats.csv\",\n",
    "            \"fielding\": \"fielding_stats.csv\",\n",
    "            \"allround\": \"allround_stats.csv\",\n",
    "            \"personal_info\": \"personal_info.csv\"\n",
    "                        }\n",
    "\n",
    "        if stat_type not in file_name_map:\n",
    "            print(f\"❌ Error: Invalid stat_type '{stat_type}'. Choose from {list(file_name_map.keys())}.\")\n",
    "            return None\n",
    "\n",
    "        # Define the GCS blob name based on the structure\n",
    "        source_blob_name = f\"{self.player_name}/{self.data_type}/{file_name_map[stat_type]}\"\n",
    "\n",
    "        # Initialize GCS client and fetch the file\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(source_blob_name)\n",
    "\n",
    "        try:\n",
    "            csv_data = blob.download_as_text()\n",
    "            df = pd.read_csv(BytesIO(csv_data.encode()))\n",
    "            print(f\"✅ Successfully downloaded {stat_type} data from gs://{bucket_name}/{source_blob_name}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error downloading {stat_type} stats: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def load_data(self, bucket_name):\n",
    "        \"\"\"\n",
    "        Uploads data to GCS in a structured format.\n",
    "        - bucket_name: Name of the GCS bucket.\n",
    "        \"\"\"\n",
    "        print(f\"🚀 Uploading {self.player_name}'s {self.data_type} data to GCS...\")\n",
    "\n",
    "        # Ensure bucket exists before uploading\n",
    "        self.ensure_bucket_exists(bucket_name)\n",
    "\n",
    "        # Define the base folder (`player_name/raw/` or `player_name/tf/`)\n",
    "        base_folder = f\"{self.player_name}/{self.data_type}/\"\n",
    "\n",
    "        if self.battingstats is not None:\n",
    "            self.upload_df_to_gcs(bucket_name, base_folder + \"batting_stats.csv\", self.battingstats)\n",
    "\n",
    "        if self.bowlingstats is not None:\n",
    "            self.upload_df_to_gcs(bucket_name, base_folder + \"bowling_stats.csv\", self.bowlingstats)\n",
    "\n",
    "        if self.fieldingstats is not None:\n",
    "            self.upload_df_to_gcs(bucket_name, base_folder + \"fielding_stats.csv\", self.fieldingstats)\n",
    "\n",
    "        if self.allroundstats is not None:\n",
    "            self.upload_df_to_gcs(bucket_name, base_folder + \"allround_stats.csv\", self.allroundstats)\n",
    "\n",
    "        if self.player_info is not None:\n",
    "            self.upload_df_to_gcs(bucket_name, base_folder + \"personal_info.csv\", self.player_info)\n",
    "\n",
    "        print(f\"✅ All {self.data_type} data successfully uploaded to GCS in gs://{bucket_name}/{base_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WebDriver...\n",
      "Extracting Virat Kohli's player URL and Player ID....\n",
      "Extraction Successful for Virat Kohli.\n",
      "Time taken to extract URL: 9.47 seconds\n",
      "WebDriver closed successfully.\n",
      "Starting extraction of Virat Kohli's batting stats....\n",
      "Extracted 646 records in 134.75 seconds\n",
      "Starting extraction of Virat Kohli's bowling stats....\n",
      "Extracted 663 records in 100.42 seconds\n",
      "Starting extraction of Virat Kohli's personal info....\n",
      "Extracted player info in 2.47 seconds\n",
      "Starting extraction of Virat Kohli's fielding stats....\n",
      "Extracted 663 records in 116.01 seconds\n"
     ]
    }
   ],
   "source": [
    "#scraping data\n",
    "player_name = \"Virat Kohli\"\n",
    "virat_raw = Cricketer_Stats_Scraper(player_name)\n",
    "virat_raw.get_player_stats()\n",
    "\n",
    "#saving raw data to bucket\n",
    "bucket_name = \"cricketer_stats\"\n",
    "\n",
    "virat_raw_loader = CricketerStatsLoader(player_name)\n",
    "virat_raw_loader.battingstats = virat_raw.battingstats\n",
    "virat_raw_loader.bowlingstats = virat_raw.bowlingstats\n",
    "virat_raw_loader.fieldingstats = virat_raw.fieldingstats\n",
    "virat_raw_loader.player_info = virat_raw.player_info\n",
    "\n",
    "virat_raw_loader.load_data(bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading raw data from bucket and assigning to transformer object\n",
    "virat_raw_downloader = CricketerStatsLoader(player_name, data_type=\"raw\")\n",
    "virat_tf = Cricketer_Stats_Transformer(player_name)\n",
    "\n",
    "virat_tf.battingstats = virat_raw_downloader.download_df_from_gcs(bucket_name, \"batting\")\n",
    "virat_tf.bowlingstats = virat_raw_downloader.download_df_from_gcs(bucket_name, \"bowling\")\n",
    "virat_tf.fieldingstats = virat_raw_downloader.download_df_from_gcs(bucket_name, \"fielding\")\n",
    "virat_tf.allroundstats = virat_raw_downloader.download_df_from_gcs(bucket_name, \"allround\")\n",
    "virat_tf.player_info = virat_raw_downloader.download_df_from_gcs(bucket_name, \"personal_info\")\n",
    "\n",
    "#transforming data\n",
    "virat_tf.process_data()\n",
    "\n",
    "#saving transformed data to bucket\n",
    "virat_tf_loader = CricketerStatsLoader(player_name, data_type=\"tf\")\n",
    "\n",
    "virat_tf_loader.battingstats = virat_tf.battingstats\n",
    "virat_tf_loader.bowlingstats = virat_tf.bowlingstats\n",
    "virat_tf_loader.fieldingstats = virat_tf.fieldingstats\n",
    "virat_tf_loader.allroundstats = virat_tf.allroundstats\n",
    "virat_tf_loader.player_info = virat_tf.player_info\n",
    "\n",
    "virat_tf_loader.load_data(bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
