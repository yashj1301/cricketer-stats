{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "class ScrapeData:\n",
    "\n",
    "    def __init__(self, player_name):\n",
    "        self.player_name = player_name\n",
    "        self.player_id = None\n",
    "        self.player_url = None\n",
    "    \n",
    "        # Initialize class variables for storing stats\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.player_info = None\n",
    "\n",
    "        # Set up the WebDriver and open the search URL\n",
    "        options = uc.ChromeOptions()\n",
    "        options.add_argument(\"--window-size=1920,1080\")\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "        print(\"Setting up WebDriver...\")\n",
    "        self.driver = uc.Chrome(options=options)        \n",
    "\n",
    "        # Call get_player_url() to fetch the player's URL and ID when the object is initialized\n",
    "        self.get_player_url()\n",
    "\n",
    "    def get_player_url(self):\n",
    "        start_time = time.time()\n",
    "        print(f\"Extracting {self.player_name}'s player URL and Player ID....\")\n",
    "        search_url = f\"https://search.espncricinfo.com/ci/content/site/search.html?search={self.player_name.lower().replace(' ', '%20')};type=player\"\n",
    "        self.driver.get(search_url)\n",
    "\n",
    "        try:\n",
    "            player_link_element = self.driver.find_element(By.CSS_SELECTOR, \"h3.name.link-cta a\")\n",
    "            self.player_url = player_link_element.get_attribute(\"href\")\n",
    "            self.player_id = self.player_url.split('-')[-1]\n",
    "            print(f\"Extraction Successful for {self.player_name}.\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken to extract URL: {end_time - start_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting {self.player_name}'s url:\", e)\n",
    "            return None, None\n",
    "\n",
    "    def extract_inns_data(self, record_type):\n",
    "        start_time = time.time()\n",
    "        print(f\"Starting extraction of {self.player_name}'s {record_type} stats....\")\n",
    "        \n",
    "        # Construct the search URL based on record_type (batting, bowling, etc.)\n",
    "        search_url = f\"https://stats.espncricinfo.com/ci/engine/player/{self.player_id}.html?class=11;template=results;type={record_type};view=innings\"\n",
    "        \n",
    "        # Open the URL\n",
    "        self.driver.get(search_url)\n",
    "\n",
    "        # Step 1: Extract the headers of the table\n",
    "        headers = self.driver.find_elements(By.CSS_SELECTOR, \"thead tr.headlinks th\")\n",
    "        header_names = [header.text for header in headers if header.text != ''] + ['Match id']  # Add match_id column name\n",
    "        \n",
    "        # Step 2: Extract the data from the 4th tbody\n",
    "        rows = self.driver.find_elements(By.XPATH, \"(//tbody)[4]//tr\")\n",
    "        \n",
    "        # Step 3: Extract the data column-wise and store it in a list\n",
    "        player_data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            row_data = [cell.text for cell in cells if cell.text != '']\n",
    "            player_data.append(row_data)\n",
    "        \n",
    "        # Step 4: Create a DataFrame from the extracted data\n",
    "        innings_data = pd.DataFrame(player_data, columns=header_names)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Extracted {innings_data.shape[0]} records in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        return innings_data\n",
    "\n",
    "    def extract_player_info(self):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting extraction of {self.player_name}'s personal info....\")\n",
    "            \n",
    "            # Start by opening the player info URL\n",
    "            self.driver.get(self.player_url)\n",
    "\n",
    "            # Step 1: Extract headers within the specified div tag\n",
    "            headers = self.driver.find_elements(By.XPATH, \"//div[@class='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8']//p[@class='ds-text-tight-m ds-font-regular ds-uppercase ds-text-typo-mid3']\")\n",
    "            header_names = ['Player ID','Player URL']+[header.text for header in headers]\n",
    "\n",
    "            # Step 2: Extract values within the specified div tag\n",
    "            values = self.driver.find_elements(By.XPATH, \"//div[@class='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8']//span[@class='ds-text-title-s ds-font-bold ds-text-typo']\")\n",
    "            value_texts = [self.player_id,self.player_url]+[value.text for value in values]\n",
    "\n",
    "            # Step 3: Create a DataFrame from the extracted data\n",
    "            player_info = pd.DataFrame([value_texts], columns=header_names)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"Extracted player info in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            return player_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting {self.player_name}'s personal info:\", e)\n",
    "            return None\n",
    "\n",
    "    def get_player_stats(self, stats_type=\"all\"):\n",
    "        try:\n",
    "            # Ensure that player ID or player URL is available\n",
    "            if not (self.player_id or self.player_url):\n",
    "                print(\"Player ID is not available. Run get_player_url() first.\")\n",
    "                return\n",
    "            \n",
    "            # Fetch personal information if 'personal_info' is passed\n",
    "            if stats_type == \"personal_info\":\n",
    "                self.player_info = self.extract_player_info()\n",
    "            \n",
    "            # Fetch batting stats if 'all' or 'batting' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"batting\":\n",
    "                self.battingstats = self.extract_inns_data('batting')\n",
    "\n",
    "            # Fetch bowling stats if 'all' or 'bowling' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"bowling\":\n",
    "                self.bowlingstats = self.extract_inns_data('bowling')\n",
    "\n",
    "            # Check if the player is an all-rounder and fetch all-round stats\n",
    "            if stats_type == \"all\" or stats_type == \"allround\":\n",
    "                self.player_info = self.extract_player_info()\n",
    "                if self.player_info is not None and 'allround' in self.player_info['PLAYING ROLE'][0].lower():\n",
    "                    self.allroundstats = self.extract_inns_data('allround')\n",
    "\n",
    "            # Fetch fielding stats if 'all' or 'fielding' is passed\n",
    "            if stats_type == \"all\" or stats_type == \"fielding\":\n",
    "                self.fieldingstats = self.extract_inns_data('fielding')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting stats for {self.player_name}: \", e)\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "            print(\"WebDriver closed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error while closing the WebDriver:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting Ground Information\n",
    "\n",
    "The following functions are built to extract ground information. However, these are very resource-intensive, so we will take it up later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_links(player_id):\n",
    "    \"\"\"\n",
    "    This function extracts ground links from the player innings data, ensuring no duplicate ground info is scraped.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize the DataFrame to store ground info\n",
    "    ground_info_df = pd.DataFrame(columns=[\"Ground ID\", \"Stadium Name\", \"Location\", \"Home Team\", \"Image URL\"])\n",
    "\n",
    "    # Set up the WebDriver for scraping\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    # Scrape Player Stats Page\n",
    "    search_url = f\"https://stats.espncricinfo.com/ci/engine/player/{player_id}.html?class=11;template=results;type=batting;view=innings\"\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Extract ground links from innings data\n",
    "    rows = driver.find_elements(By.XPATH, \"(//tbody)[4]//tr\")\n",
    "    ground_links = []\n",
    "    \n",
    "    for row in rows:\n",
    "        try:\n",
    "            ground_name_element = row.find_element(By.XPATH, \".//td[contains(@class, 'left')][2]/a\")\n",
    "            ground_name = ground_name_element.text\n",
    "            ground_link = ground_name_element.get_attribute('href')\n",
    "            ground_links.append((ground_name, ground_link))\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting ground data: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Step 2: Check if the ground has already been scraped (exists in ground_info DataFrame)\n",
    "    for ground_name, ground_link in ground_links:\n",
    "        if ground_name not in ground_info_df['Stadium Name'].values:\n",
    "            # Create a new DataFrame for the new ground\n",
    "            new_data = pd.DataFrame({\"Stadium Name\": [ground_name], \"Ground Link\": [ground_link]})\n",
    "            ground_info_df = pd.concat([ground_info_df, new_data], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Ground {ground_name} has already been scraped. Skipping.\")\n",
    "\n",
    "    # Step 3: Extract ground info for each link and append it to the ground_info_df\n",
    "    for ground_link in ground_info_df['Ground Link']:\n",
    "        ground_info_df = extract_ground_info(ground_link, ground_info_df)\n",
    "    \n",
    "    driver.quit()\n",
    "    return ground_info_df\n",
    "\n",
    "def extract_ground_info(ground_url, ground_info_df):\n",
    "    \"\"\"\n",
    "    This function extracts ground information (ID, stadium name, location, home team, image URL)\n",
    "    from a given ground URL and appends the data to the provided dataframe.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Set up the WebDriver for scraping ground info\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    driver.get(ground_url)\n",
    "    \n",
    "    try:\n",
    "        # 1. Ground ID (numeric portion of the URL)\n",
    "        ground_id = ground_url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # 2. Ground image URL\n",
    "        img_element = driver.find_element(By.XPATH, \"//div[@class='ds-p-0']//img[1]\")\n",
    "        image_url = img_element.get_attribute(\"src\")\n",
    "        \n",
    "        # 3. Stadium Name\n",
    "        stadium_name = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-title-m') and contains(@class, 'ds-font-bold')]\").text\n",
    "        \n",
    "        # 4. Location (City)\n",
    "        location = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-compact-s') and contains(@class, 'ds-font-bold')]\").text.strip().replace(\"\\n\", \", \")\n",
    "        \n",
    "        # 5. Home Team (Country)\n",
    "        home_team_text = driver.find_element(By.XPATH, \"//span[contains(text(), 'Grounds in')]\").text\n",
    "        home_team = home_team_text.split(\"Grounds in\")[-1].strip()\n",
    "        \n",
    "        # Prepare the ground info as a dictionary\n",
    "        ground_info = pd.DataFrame({\n",
    "            \"Ground ID\": [ground_id],\n",
    "            \"Stadium Name\": [stadium_name],\n",
    "            \"Location\": [location],\n",
    "            \"Home Team\": [home_team],\n",
    "            \"Image URL\": [image_url]\n",
    "        })\n",
    "        \n",
    "        # Append the ground info to the DataFrame\n",
    "        ground_info_df = pd.concat([ground_info_df,ground_info], ignore_index=True)\n",
    "        print(f\"Extracted info for ground {stadium_name} in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while extracting info for {ground_url}: {e}\")\n",
    "    \n",
    "    driver.quit()\n",
    "    return ground_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='ds-p-0']//img\"}\n",
      "  (Session info: chrome=135.0.7049.85); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00B88073+60707]\n",
      "\tGetHandleVerifier [0x00B880B4+60772]\n",
      "\t(No symbol) [0x009B0683]\n",
      "\t(No symbol) [0x009F8660]\n",
      "\t(No symbol) [0x009F89FB]\n",
      "\t(No symbol) [0x00A41022]\n",
      "\t(No symbol) [0x00A1D094]\n",
      "\t(No symbol) [0x00A3E824]\n",
      "\t(No symbol) [0x00A1CE46]\n",
      "\t(No symbol) [0x009EC5D3]\n",
      "\t(No symbol) [0x009ED424]\n",
      "\tGetHandleVerifier [0x00DCBB53+2435075]\n",
      "\tGetHandleVerifier [0x00DC70F3+2416035]\n",
      "\tGetHandleVerifier [0x00DE349C+2531660]\n",
      "\tGetHandleVerifier [0x00B9F145+155125]\n",
      "\tGetHandleVerifier [0x00BA5AED+182173]\n",
      "\tGetHandleVerifier [0x00B8F948+91640]\n",
      "\tGetHandleVerifier [0x00B8FAF0+92064]\n",
      "\tGetHandleVerifier [0x00B7A5B0+4704]\n",
      "\tBaseThreadInitThunk [0x75D35D49+25]\n",
      "\tRtlInitializeExceptionChain [0x7792CFFB+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x7792CF81+561]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ground_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 39\u001b[0m\n\u001b[0;32m     29\u001b[0m     ground_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ground_id],\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStadium Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: [stadium_name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage URL\u001b[39m\u001b[38;5;124m\"\u001b[39m: [image_url]\n\u001b[0;32m     35\u001b[0m         })\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e : \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mground_info\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ground_info' is not defined"
     ]
    }
   ],
   "source": [
    "ground_url = 'https://www.espncricinfo.com/cricket-grounds/rangiri-dambulla-international-stadium-59368'\n",
    "\n",
    "# Set up the WebDriver for scraping ground info\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "driver.get(ground_url)\n",
    "    \n",
    "try:\n",
    "    # 1. Ground ID (numeric portion of the URL)\n",
    "    ground_id = ground_url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "    # 2. Ground image URL\n",
    "    img_element = driver.find_element(By.XPATH, \"//div[@class='ds-p-0']//img\")\n",
    "    image_url = img_element.get_attribute(\"src\")\n",
    "        \n",
    "        # 3. Stadium Name\n",
    "    stadium_name = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-title-m') and contains(@class, 'ds-font-bold')]\").text\n",
    "        \n",
    "    # 4. Location (City)\n",
    "    location = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-text-compact-s') and contains(@class, 'ds-font-bold')]\").text.strip().replace(\"\\n\", \", \")\n",
    "        \n",
    "    # 5. Home Team (Country)\n",
    "    home_team_text = driver.find_element(By.XPATH, \"//span[contains(text(), 'Grounds in')]\").text\n",
    "    home_team = home_team_text.split(\"Grounds in\")[-1].strip()\n",
    "        \n",
    "    # Prepare the ground info as a dictionary\n",
    "    ground_info = pd.DataFrame({\n",
    "            \"Ground ID\": [ground_id],\n",
    "            \"Stadium Name\": [stadium_name],\n",
    "            \"Location\": [location],\n",
    "            \"Home Team\": [home_team],\n",
    "            \"Image URL\": [image_url]\n",
    "        })\n",
    "\n",
    "except Exception as e : print(e)\n",
    "    \n",
    "ground_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id = 253802\n",
    "grounds = extract_ground_links(player_id)\n",
    "\n",
    "grounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TransformData:\n",
    "    \n",
    "    def __init__(self, player_name):\n",
    "        self.player_name = player_name\n",
    "        self.player_info = None\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.player_id = None\n",
    "        self.player_url = None\n",
    "\n",
    "    #transforming data\n",
    "\n",
    "    def transform_data(self,df):\n",
    "        \n",
    "        #STEP 1: Replacing incorrect values. \n",
    "        repl_dict = {\n",
    "            r'\\*': '',       \n",
    "            r'^DNB$': np.nan,  \n",
    "            r'^TDNB$': np.nan, \n",
    "            r'^DNF$': np.nan,  \n",
    "            r'^TDNF$': np.nan, \n",
    "            r'^-$': np.nan,    \n",
    "            r'^sub$': np.nan   \n",
    "                    }\n",
    "\n",
    "        df = df.replace(repl_dict,regex=True)\n",
    "\n",
    "        #STEP 2: Opposition column\n",
    "        df['Format'] = df['Opposition'].str.extract(r'(^.*?)\\sv\\s')\n",
    "        df['Opposition'] = df['Opposition'].str.extract(r'\\sv\\s(.*?$)')\n",
    "\n",
    "        #STEP 3: Ground column\n",
    "        ground_mapping = {\n",
    "        \"Colombo (SSC)\": \"Colombo\",\n",
    "        \"Colombo (PSS)\": \"Colombo\",\n",
    "        \"Colombo (RPS)\": \"Colombo\",\n",
    "        \"Eden Gardens\": \"Kolkata\",\n",
    "        \"Wankhede\": \"Mumbai\",\n",
    "        \"Brabourne\": \"Mumbai\",\n",
    "        \"Kingston\": \"Kingston Jamaica\",\n",
    "        \"The Oval\": \"London\",\n",
    "        \"Lord's\": \"London\",\n",
    "        \"W.A.C.A\": \"Perth\",\n",
    "        \"Dharamsala\": \"Dharamshala\",\n",
    "        \"Hamilton\": \"Hamilton Waikato\",\n",
    "        \"Fatullah\": \"Fatullah Dhaka\",\n",
    "        \"Providence\": \"Providence Guyana\",\n",
    "        \"Dubai (DICS)\": \"Dubai\",\n",
    "        \"Chattogram\": \"Chattogram Chittagong\"\n",
    "        }\n",
    "\n",
    "        df['Ground']=df['Ground'].replace(ground_mapping)\n",
    "        df = df.rename(columns={'Ground':'Location'})\n",
    "\n",
    "        #STEP 4: START DATE\n",
    "        df['Start Date'] = df['Start Date'].astype('datetime64[ns]')\n",
    "\n",
    "        #STEP 5: MATCH ID\n",
    "        df['Match id']='#'+df['Match id'].str.extract(r'(\\d+$)')\n",
    "        df = df.rename(columns={'Match id':'Match ID'})\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def final_df(self, df, common_cols, custom_cols):\n",
    "\n",
    "        dtype_mapping = {\n",
    "\n",
    "                # Common Columns\n",
    "                'Match ID': 'string',\n",
    "                'Start Date': 'datetime64[ns]',\n",
    "                'Format': 'string',\n",
    "                'Inns': 'Int64',  # Allows NaN handling\n",
    "                'Opposition': 'string',\n",
    "                'Location': 'string',\n",
    "                \n",
    "                # Batting Columns\n",
    "                'Pos': 'Int64',\n",
    "                'Runs': 'Int64',\n",
    "                'BF': 'Int64',\n",
    "                '4s': 'Int64',\n",
    "                '6s': 'Int64',\n",
    "                'SR': 'float64',\n",
    "                'Mins': 'Int64',\n",
    "                'Dismissal': 'string',\n",
    "\n",
    "                # Bowling Columns\n",
    "                'Overs': 'float64',\n",
    "                'Mdns': 'Int64',\n",
    "                'Runs': 'Int64',\n",
    "                'Wkts': 'Int64',\n",
    "                'Econ': 'float64',\n",
    "\n",
    "                # Fielding Columns\n",
    "                'Dis': 'Int64',\n",
    "                'Ct': 'Int64',\n",
    "\n",
    "                # Allround Columns\n",
    "                'Score': 'string',  # Could be runs or DNB, TDNB\n",
    "                'Conc': 'Int64',\n",
    "                'St': 'Int64'\n",
    "            }\n",
    "\n",
    "        if df is not None:\n",
    "            df = self.transform_data(df)\n",
    "\n",
    "            # Select the necessary columns\n",
    "            df = df[common_cols[:-2] + custom_cols + common_cols[-2:]]\n",
    "\n",
    "            # Apply type casting\n",
    "            for col in df.columns:\n",
    "                if col in dtype_mapping:\n",
    "                    try:\n",
    "                        df[col] = df[col].astype(dtype_mapping[col])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Data type casting failed for column {col}: {e}\")\n",
    "\n",
    "            return df\n",
    "\n",
    "\n",
    "    def process_data(self,type=\"all\"):\n",
    "\n",
    "        common = ['Match ID','Start Date','Format','Inns','Opposition','Location']\n",
    "        batcols = ['Pos','Runs','BF','4s','6s','SR','Mins','Dismissal']\n",
    "        bowlcols = ['Pos','Overs','Mdns','Runs','Wkts','Econ']\n",
    "        fieldcols = ['Dis','Ct']\n",
    "        allroundcols = ['Score','Overs','Conc','Wkts','Ct','St']\n",
    "\n",
    "        try:\n",
    "        \n",
    "            # Process batting stats\n",
    "            if type == 'all' or type == 'batting':\n",
    "                print(f\"Processing {self.player_name}'s batting stats...\")\n",
    "                self.battingstats = self.final_df(self.battingstats, common, batcols)\n",
    "                print(f\"Batting stats processed successfully.\")\n",
    "\n",
    "            # Process bowling stats\n",
    "            if type == 'all' or type == 'bowling':\n",
    "                print(f\"Processing {self.player_name}'s bowling stats...\")\n",
    "                self.bowlingstats = self.final_df(self.bowlingstats, common, bowlcols)\n",
    "                print(f\"Bowling stats processed successfully.\")\n",
    "\n",
    "            # Process fielding stats\n",
    "            if type == 'all' or type == 'fielding':\n",
    "                print(f\"Processing {self.player_name}'s fielding stats...\")\n",
    "                self.fieldingstats = self.final_df(self.fieldingstats, common, fieldcols)\n",
    "                print(f\"Fielding stats processed successfully.\")\n",
    "\n",
    "            # Process allround stats\n",
    "            if type == 'all' or type == 'allround':\n",
    "                if self.player_info is not None and 'allround' in self.player_info['PLAYING ROLE'][0].lower():\n",
    "                    print(f\"Processing {self.player_name}'s all-round stats...\")\n",
    "                    self.allroundstats = self.final_df(self.allroundstats, common, allroundcols)\n",
    "                    print(f\"All-round stats processed successfully.\")\n",
    "\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing data for {self.player_name}: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore.exceptions\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load AWS credentials from .env\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "class LoadData:\n",
    "\n",
    "    def __init__(self, player_name, data_type=\"raw\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the CricketerStatsLoader with player name and data type.\n",
    "        Args:\n",
    "            player_name (str): Name of the player.\n",
    "            data_type (str): Type of data ('raw' or 'tf').\n",
    "        \"\"\"\n",
    "\n",
    "        self.player_name = player_name.lower().replace(\" \", \"_\")\n",
    "        self.data_type = data_type  # 'raw' or 'tf'\n",
    "        self.battingstats = None\n",
    "        self.bowlingstats = None\n",
    "        self.fieldingstats = None\n",
    "        self.allroundstats = None\n",
    "        self.player_info = None\n",
    "\n",
    "    def ensure_bucket_exists(self, bucket_name):\n",
    "\n",
    "        \"\"\"Checks if the S3 bucket exists, and creates it if not.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            s3.head_bucket(Bucket=bucket_name)\n",
    "            print(f\"✅ Bucket '{bucket_name}' already exists.\")\n",
    "        \n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            error_code = int(e.response[\"Error\"][\"Code\"])\n",
    "            \n",
    "            if error_code == 404:\n",
    "                print(f\"⚠️ Bucket '{bucket_name}' does not exist. Creating...\")\n",
    "                s3.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={\n",
    "                        'LocationConstraint': os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "                                            }\n",
    "                )\n",
    "                \n",
    "                print(f\"✅ Bucket '{bucket_name}' created successfully.\")\n",
    "            \n",
    "            else: raise e\n",
    "    \n",
    "    def upload_df(self, bucket_name, object_key, df):\n",
    "\n",
    "        \"\"\"Uploads a Pandas DataFrame as a CSV file to S3.\"\"\"\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            print(f\"Warning: {object_key} is empty, skipping upload.\")\n",
    "            return\n",
    "\n",
    "        csv_buffer = StringIO()\n",
    "        df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "        s3.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=object_key,\n",
    "            Body=csv_buffer.getvalue(),\n",
    "            ContentType=\"text/csv\"\n",
    "        )\n",
    "\n",
    "        print(f\" Uploaded to s3://{bucket_name}/{object_key}\")\n",
    "\n",
    "    def download_df(self, bucket_name, stat_type):\n",
    "\n",
    "        \"\"\"Downloads a cricket stat CSV from S3 into a DataFrame.\"\"\"\n",
    "\n",
    "        file_name_map = {\n",
    "            \"batting\": \"batting_stats.csv\",\n",
    "            \"bowling\": \"bowling_stats.csv\",\n",
    "            \"fielding\": \"fielding_stats.csv\",\n",
    "            \"allround\": \"allround_stats.csv\",\n",
    "            \"personal_info\": \"personal_info.csv\"\n",
    "        }\n",
    "\n",
    "        '''If 'all' is passed, download all stat types\n",
    "        if stat_type == \"all\":\n",
    "            data = {}\n",
    "            for stat in file_name_map:\n",
    "                data[stat] = self.download_df(bucket_name, stat)  # Recursively call download_df for each type\n",
    "            return data\n",
    "        '''\n",
    "\n",
    "        if stat_type not in file_name_map:\n",
    "            print(f\" Invalid stat_type '{stat_type}'.\")\n",
    "            return None\n",
    "\n",
    "        object_key = f\"{self.player_name}/{self.data_type}/{file_name_map[stat_type]}\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "            content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "            df = pd.read_csv(StringIO(content))\n",
    "            print(f\" Downloaded from s3://{bucket_name}/{object_key}\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {stat_type} stats: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_data(self, bucket_name, load_type, stat_type=\"all\"):\n",
    "    \n",
    "        \"\"\"\n",
    "        Loads cricket stats data to/from S3.\n",
    "\n",
    "        Args:\n",
    "            bucket_name (str): Name of the S3 bucket.\n",
    "            load_type (str): Type of load operation ('upload' or 'download').\n",
    "            stat_type (str): Type of stats to load ('all', 'batting', 'bowling', 'fielding', 'allround', 'personal_info').\n",
    "        \"\"\"            \n",
    "        \n",
    "        if load_type not in [\"upload\", \"download\"]:\n",
    "            print(f\"Invalid load type '{load_type}'. Must be 'upload' or 'download'.\")\n",
    "            return\n",
    "\n",
    "        if stat_type not in [\"all\", \"batting\", \"bowling\", \"fielding\", \"allround\", \"personal_info\"]:\n",
    "            print(f\"Invalid stat type '{stat_type}'. Must be 'all', 'batting', 'bowling', 'fielding', 'allround', or 'personal_info'.\")\n",
    "            return\n",
    "\n",
    "        # Ensure the S3 bucket exists\n",
    "        self.ensure_bucket_exists(bucket_name)\n",
    "\n",
    "        # Perform the upload operation\n",
    "        if load_type == \"upload\":\n",
    "\n",
    "            print(f\"Uploading {self.player_name}'s {self.data_type} {stat_type} data to S3...\")\n",
    "            \n",
    "            base_folder = f\"{self.player_name}/{self.data_type}/\"\n",
    "\n",
    "            if self.battingstats is not None and stat_type in [\"all\", \"batting\"]:\n",
    "                self.upload_df(bucket_name, base_folder + \"batting_stats.csv\", self.battingstats)\n",
    "\n",
    "            if self.bowlingstats is not None and stat_type in [\"all\", \"bowling\"]:\n",
    "                self.upload_df(bucket_name, base_folder + \"bowling_stats.csv\", self.bowlingstats)\n",
    "\n",
    "            if self.fieldingstats is not None and stat_type in [\"all\", \"fielding\"]:\n",
    "                self.upload_df(bucket_name, base_folder + \"fielding_stats.csv\", self.fieldingstats)\n",
    "\n",
    "            if self.allroundstats is not None and stat_type in [\"all\", \"allround\"]:\n",
    "                self.upload_df(bucket_name, base_folder + \"allround_stats.csv\", self.allroundstats)\n",
    "\n",
    "            if self.player_info is not None and stat_type in [\"all\", \"personal_info\"]:\n",
    "                self.upload_df(bucket_name, base_folder + \"personal_info.csv\", self.player_info)\n",
    "\n",
    "            print(f\"All {self.data_type} data uploaded to s3://{bucket_name}/{base_folder}\")\n",
    "\n",
    "        # Perform the download operation\n",
    "        elif load_type == \"download\":\n",
    "\n",
    "            print(f\"Downloading {self.player_name}'s {self.data_type} data from S3...\")\n",
    "\n",
    "            if stat_type in [\"all\", \"personal_info\"]:\n",
    "                self.player_info = self.download_df(bucket_name, \"personal_info\")\n",
    "\n",
    "            if stat_type in [\"all\", \"batting\"]:\n",
    "                self.battingstats = self.download_df(bucket_name, \"batting\")\n",
    "\n",
    "            if stat_type in [\"all\", \"bowling\"]:\n",
    "                self.bowlingstats = self.download_df(bucket_name, \"bowling\")\n",
    "\n",
    "            if stat_type in [\"all\", \"fielding\"]:\n",
    "                self.fieldingstats = self.download_df(bucket_name, \"fielding\")\n",
    "\n",
    "            if stat_type in [\"all\", \"allround\"]:\n",
    "\n",
    "                # Download allround stats if PLAYING ROLE is \"Allrounder\"\n",
    "                if self.player_info is not None and \"Allrounder\" in self.player_info[\"PLAYING ROLE\"].values:\n",
    "                    self.allroundstats = self.download_df(bucket_name, \"allround\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Warning: Player {self.player_name} is not an Allrounder. Skipping allround stats download.\")\n",
    "                    self.allroundstats = None\n",
    "                \n",
    "            print(f\"All {self.data_type} data downloaded from s3://{bucket_name}/{self.player_name}/{self.data_type}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virat Kohli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Bucket 'cricketer-stats' does not exist. Creating...\n",
      "✅ Bucket 'cricketer-stats' created successfully.\n",
      "Uploading virat_kohli's raw all data to S3...\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/raw/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/raw/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/raw/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/raw/personal_info.csv\n",
      "All raw data uploaded to s3://cricketer-stats/virat_kohli/raw/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 1: Scrape raw data ---\n",
    "player_name = \"Virat Kohli\"\n",
    "virat_raw = ScrapeData(player_name)\n",
    "virat_raw.get_player_stats()\n",
    "\n",
    "# --- 🔹 Step 2: Upload raw data to S3 ---\n",
    "bucket_name = \"cricketer-stats\"\n",
    "virat_raw_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "virat_raw_loader.battingstats = virat_raw.battingstats\n",
    "virat_raw_loader.bowlingstats = virat_raw.bowlingstats\n",
    "virat_raw_loader.fieldingstats = virat_raw.fieldingstats\n",
    "virat_raw_loader.allroundstats = virat_raw.allroundstats\n",
    "virat_raw_loader.player_info = virat_raw.player_info\n",
    "\n",
    "virat_raw_loader.load_data(bucket_name, load_type=\"upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Downloading virat_kohli's raw data from S3...\n",
      " Downloaded from s3://cricketer-stats/virat_kohli/raw/personal_info.csv\n",
      " Downloaded from s3://cricketer-stats/virat_kohli/raw/batting_stats.csv\n",
      " Downloaded from s3://cricketer-stats/virat_kohli/raw/bowling_stats.csv\n",
      " Downloaded from s3://cricketer-stats/virat_kohli/raw/fielding_stats.csv\n",
      "Warning: Player virat_kohli is not an Allrounder. Skipping allround stats download.\n",
      "All raw data downloaded from s3://cricketer-stats/virat_kohli/raw/\n",
      "Processing Virat Kohli's batting stats...\n",
      "Batting stats processed successfully.\n",
      "Processing Virat Kohli's bowling stats...\n",
      "Bowling stats processed successfully.\n",
      "Processing Virat Kohli's fielding stats...\n",
      "Fielding stats processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 3: Download raw data from S3 ---\n",
    "virat_tf = TransformData(player_name)\n",
    "virat_tf_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "virat_tf_loader.load_data(bucket_name, load_type=\"download\", stat_type=\"all\")\n",
    "\n",
    "virat_tf.battingstats = virat_tf_loader.battingstats\n",
    "virat_tf.bowlingstats = virat_tf_loader.bowlingstats\n",
    "virat_tf.fieldingstats = virat_tf_loader.fieldingstats\n",
    "virat_tf.allroundstats = virat_tf_loader.allroundstats\n",
    "virat_tf.player_info = virat_tf_loader.player_info\n",
    "\n",
    "# --- 🔹 Step 4: Transform the data ---\n",
    "virat_tf.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Uploading virat_kohli's tf all data to S3...\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/tf/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/tf/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/tf/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/virat_kohli/tf/personal_info.csv\n",
      "All tf data uploaded to s3://cricketer-stats/virat_kohli/tf/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 5: Upload transformed data to S3 ---\n",
    "virat_tf_loader = LoadData(player_name, data_type=\"tf\")\n",
    "\n",
    "virat_tf_loader.battingstats = virat_tf.battingstats\n",
    "virat_tf_loader.bowlingstats = virat_tf.bowlingstats\n",
    "virat_tf_loader.fieldingstats = virat_tf.fieldingstats\n",
    "virat_tf_loader.allroundstats = virat_tf.allroundstats\n",
    "virat_tf_loader.player_info = virat_tf.player_info\n",
    "\n",
    "virat_tf_loader.load_data(bucket_name, load_type=\"upload\", stat_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacques Kallis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WebDriver...\n",
      "Extracting Jacques Kallis's player URL and Player ID....\n",
      "Extraction Successful for Jacques Kallis.\n",
      "Time taken to extract URL: 4.13 seconds\n",
      "Starting extraction of Jacques Kallis's batting stats....\n",
      "Extracted 646 records in 138.87 seconds\n",
      "Starting extraction of Jacques Kallis's bowling stats....\n",
      "Extracted 668 records in 118.81 seconds\n",
      "Starting extraction of Jacques Kallis's personal info....\n",
      "Extracted player info in 4.10 seconds\n",
      "Starting extraction of Jacques Kallis's allround stats....\n",
      "Extracted 1314 records in 247.82 seconds\n",
      "Starting extraction of Jacques Kallis's fielding stats....\n",
      "Extracted 668 records in 110.29 seconds\n",
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Uploading jacques_kallis's raw all data to S3...\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/raw/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/raw/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/raw/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/raw/allround_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/raw/personal_info.csv\n",
      "All raw data uploaded to s3://cricketer-stats/jacques_kallis/raw/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 1: Scrape raw data ---\n",
    "player_name = \"Jacques Kallis\"\n",
    "kallis_raw = ScrapeData(player_name)\n",
    "kallis_raw.get_player_stats()\n",
    "\n",
    "# --- 🔹 Step 2: Upload raw data to S3 ---\n",
    "bucket_name = \"cricketer-stats\"\n",
    "kallis_raw_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "kallis_raw_loader.battingstats = kallis_raw.battingstats\n",
    "kallis_raw_loader.bowlingstats = kallis_raw.bowlingstats\n",
    "kallis_raw_loader.fieldingstats = kallis_raw.fieldingstats\n",
    "kallis_raw_loader.allroundstats = kallis_raw.allroundstats\n",
    "kallis_raw_loader.player_info = kallis_raw.player_info\n",
    "\n",
    "kallis_raw_loader.load_data(bucket_name, load_type=\"upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Downloading jacques_kallis's raw data from S3...\n",
      " Downloaded from s3://cricketer-stats/jacques_kallis/raw/personal_info.csv\n",
      " Downloaded from s3://cricketer-stats/jacques_kallis/raw/batting_stats.csv\n",
      " Downloaded from s3://cricketer-stats/jacques_kallis/raw/bowling_stats.csv\n",
      " Downloaded from s3://cricketer-stats/jacques_kallis/raw/fielding_stats.csv\n",
      " Downloaded from s3://cricketer-stats/jacques_kallis/raw/allround_stats.csv\n",
      "All raw data downloaded from s3://cricketer-stats/jacques_kallis/raw/\n",
      "Processing Jacques Kallis's batting stats...\n",
      "Batting stats processed successfully.\n",
      "Processing Jacques Kallis's bowling stats...\n",
      "Bowling stats processed successfully.\n",
      "Processing Jacques Kallis's fielding stats...\n",
      "Fielding stats processed successfully.\n",
      "Processing Jacques Kallis's all-round stats...\n",
      "All-round stats processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 3: Download raw data from S3 ---\n",
    "kallis_tf = TransformData(player_name)\n",
    "kallis_tf_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "kallis_tf_loader.load_data(bucket_name, load_type=\"download\", stat_type=\"all\")\n",
    "\n",
    "kallis_tf.battingstats = kallis_tf_loader.battingstats\n",
    "kallis_tf.bowlingstats = kallis_tf_loader.bowlingstats\n",
    "kallis_tf.fieldingstats = kallis_tf_loader.fieldingstats\n",
    "kallis_tf.allroundstats = kallis_tf_loader.allroundstats\n",
    "kallis_tf.player_info = kallis_tf_loader.player_info\n",
    "\n",
    "# --- 🔹 Step 4: Transform the data ---\n",
    "kallis_tf.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Uploading jacques_kallis's tf all data to S3...\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/tf/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/tf/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/tf/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/tf/allround_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jacques_kallis/tf/personal_info.csv\n",
      "All tf data uploaded to s3://cricketer-stats/jacques_kallis/tf/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 5: Upload transformed data to S3 ---\n",
    "kallis_tf_loader = LoadData(player_name, data_type=\"tf\")\n",
    "\n",
    "kallis_tf_loader.battingstats = kallis_tf.battingstats\n",
    "kallis_tf_loader.bowlingstats = kallis_tf.bowlingstats\n",
    "kallis_tf_loader.fieldingstats = kallis_tf.fieldingstats\n",
    "kallis_tf_loader.allroundstats = kallis_tf.allroundstats\n",
    "kallis_tf_loader.player_info = kallis_tf.player_info\n",
    "\n",
    "kallis_tf_loader.load_data(bucket_name, load_type=\"upload\", stat_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WebDriver...\n",
      "Extracting JM Anderson's player URL and Player ID....\n",
      "Extraction Successful for JM Anderson.\n",
      "Time taken to extract URL: 3.55 seconds\n",
      "WebDriver closed successfully.\n",
      "Starting extraction of JM Anderson's batting stats....\n",
      "Extracted 556 records in 128.56 seconds\n",
      "Starting extraction of JM Anderson's bowling stats....\n",
      "Extracted 569 records in 113.30 seconds\n",
      "Starting extraction of JM Anderson's personal info....\n",
      "Extracted player info in 4.20 seconds\n",
      "Starting extraction of JM Anderson's fielding stats....\n",
      "Extracted 569 records in 104.76 seconds\n",
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Uploading jm_anderson's raw all data to S3...\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/raw/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/raw/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/raw/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/raw/personal_info.csv\n",
      "All raw data uploaded to s3://cricketer-stats/jm_anderson/raw/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 1: Scrape raw data ---\n",
    "player_name = \"JM Anderson\"\n",
    "anderson_raw = ScrapeData(player_name)\n",
    "anderson_raw.get_player_stats()\n",
    "\n",
    "# --- 🔹 Step 2: Upload raw data to S3 ---\n",
    "bucket_name = \"cricketer-stats\"\n",
    "anderson_raw_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "anderson_raw_loader.battingstats = anderson_raw.battingstats\n",
    "anderson_raw_loader.bowlingstats = anderson_raw.bowlingstats\n",
    "anderson_raw_loader.fieldingstats = anderson_raw.fieldingstats\n",
    "anderson_raw_loader.allroundstats = anderson_raw.allroundstats\n",
    "anderson_raw_loader.player_info = anderson_raw.player_info\n",
    "\n",
    "anderson_raw_loader.load_data(bucket_name, load_type=\"upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Downloading jm_anderson's raw data from S3...\n",
      " Downloaded from s3://cricketer-stats/jm_anderson/raw/personal_info.csv\n",
      " Downloaded from s3://cricketer-stats/jm_anderson/raw/batting_stats.csv\n",
      " Downloaded from s3://cricketer-stats/jm_anderson/raw/bowling_stats.csv\n",
      " Downloaded from s3://cricketer-stats/jm_anderson/raw/fielding_stats.csv\n",
      "Warning: Player jm_anderson is not an Allrounder. Skipping allround stats download.\n",
      "All raw data downloaded from s3://cricketer-stats/jm_anderson/raw/\n",
      "Processing JM Anderson's batting stats...\n",
      "Batting stats processed successfully.\n",
      "Processing JM Anderson's bowling stats...\n",
      "Bowling stats processed successfully.\n",
      "Processing JM Anderson's fielding stats...\n",
      "Fielding stats processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 3: Download raw data from S3 ---\n",
    "anderson_tf = TransformData(player_name)\n",
    "anderson_tf_loader = LoadData(player_name, data_type=\"raw\")\n",
    "\n",
    "anderson_tf_loader.load_data(bucket_name, load_type=\"download\", stat_type=\"all\")\n",
    "\n",
    "anderson_tf.battingstats = anderson_tf_loader.battingstats\n",
    "anderson_tf.bowlingstats = anderson_tf_loader.bowlingstats\n",
    "anderson_tf.fieldingstats = anderson_tf_loader.fieldingstats\n",
    "anderson_tf.allroundstats = anderson_tf_loader.allroundstats\n",
    "anderson_tf.player_info = anderson_tf_loader.player_info\n",
    "\n",
    "# --- 🔹 Step 4: Transform the data ---\n",
    "anderson_tf.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'cricketer-stats' already exists.\n",
      "Uploading jm_anderson's tf all data to S3...\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/tf/batting_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/tf/bowling_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/tf/fielding_stats.csv\n",
      " Uploaded to s3://cricketer-stats/jm_anderson/tf/personal_info.csv\n",
      "All tf data uploaded to s3://cricketer-stats/jm_anderson/tf/\n"
     ]
    }
   ],
   "source": [
    "# --- 🔹 Step 5: Upload transformed data to S3 ---\n",
    "anderson_tf_loader = LoadData(player_name, data_type=\"tf\")\n",
    "\n",
    "anderson_tf_loader.battingstats = anderson_tf.battingstats\n",
    "anderson_tf_loader.bowlingstats = anderson_tf.bowlingstats\n",
    "anderson_tf_loader.fieldingstats = anderson_tf.fieldingstats\n",
    "anderson_tf_loader.allroundstats = anderson_tf.allroundstats\n",
    "anderson_tf_loader.player_info = anderson_tf.player_info\n",
    "\n",
    "anderson_tf_loader.load_data(bucket_name, load_type=\"upload\", stat_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_url(player_name,driver):\n",
    "    start_time = time.time()\n",
    "    print(f\"Extracting {player_name}'s player URL and Player ID....\")\n",
    "    search_url = f\"https://search.espncricinfo.com/ci/content/site/search.html?search={player_name.lower().replace(' ', '%20')};type=player\"\n",
    "    driver.get(search_url)\n",
    "\n",
    "    try:\n",
    "        player_link_element = driver.find_element(By.CSS_SELECTOR, \"h3.name.link-cta a\")\n",
    "        player_url = player_link_element.get_attribute(\"href\")\n",
    "        player_id = player_url.split('-')[-1]\n",
    "        print(f\"Extraction Successful for {player_name}.\")\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to extract URL: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        return player_url, player_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extracting {player_name}'s url:\", e)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_info(driver,player_name, player_id, player_url):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting extraction of {player_name}'s personal info....\")\n",
    "            \n",
    "            # Start by opening the player info URL\n",
    "            driver.get(player_url)\n",
    "\n",
    "            # Step 1: Extract headers within the specified div tag\n",
    "            headers = driver.find_elements(By.XPATH, \"//div//p[@class='ds-text-tight-m ds-font-regular ds-uppercase ds-text-typo-mid3']\")\n",
    "            header_names = ['Player ID','Player URL']+[header.text for header in headers]\n",
    "\n",
    "            # Step 2: Extract values within the specified div tag\n",
    "            values = driver.find_elements(By.XPATH, \"//div//span[@class='ds-text-title-s ds-font-bold ds-text-typo']\")\n",
    "            value_texts = [player_id,player_url]+[value.text for value in values]\n",
    "\n",
    "            # Step 3: Create a DataFrame from the extracted data\n",
    "            player_info = pd.DataFrame([value_texts], columns=header_names)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"Extracted player info in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            return player_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in extracting {player_name}'s personal info:\", e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_name = \"Virat Kohli\"\n",
    "player_id = 253802\n",
    "player_url = \"https://www.espncricinfo.com/cricketers/virat-kohli-253802\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Virat Kohli',\n",
       " 'November 05, 1988, Delhi',\n",
       " '36y 162d',\n",
       " 'Right hand Bat',\n",
       " 'Right arm Medium',\n",
       " 'Top order Batter']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.get(player_url)\n",
    "\n",
    "headers = driver.find_elements(By.XPATH, \"//div//p[@class='ds-text-tight-m ds-font-regular ds-uppercase ds-text-typo-mid3']\")\n",
    "[header.text for header in headers]\n",
    "\n",
    "values = driver.find_elements(By.XPATH, \"//div//span[@class='ds-text-title-s ds-font-bold ds-text-typo']\")\n",
    "[value.text for value in values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
